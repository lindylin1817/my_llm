{"context": "Instruction: Convert following Python code into BSIL code.\nInput: #Python: \ndef forward(self, primals_1: f32[768, 768], primals_2: f32[768], primals_3: f32[768, 768], primals_4: f32[768], primals_5: f32[768, 768], primals_6: f32[768], primals_7: f32[8, 512, 768], primals_8: f32[8, 1, 1, 512]):\n\nAnswer: ", "target": "#BSIL: \nforward = {{\n    !dtype=f32\n    INPUT primals_1<768, 768>,\n          primals_2<768>,\n          primals_3<768, 768>,\n          primals_4<768>,\n          primals_5<768, 768>,\n          primals_6<768>,\n          primals_7<8, 512, 768>,\n          primals_8<8, 1, 1, 512>\n    }}\n"}
{"context": "Instruction: Convert following Python code into BSIL code.\nInput: #Python: \nview: f32[4096, 768] = torch.ops.aten.view.default(primals_7, [4096, 768]);  primals_7 = None    \n\nAnswer: ", "target": "#BSIL: \nview<4096, 768> = view primals_7 {{\n          !shape=[4096, 768]\n          INPUT i0, i1: u64\n          o0, o1 = idiv i0 512\n          OUTPUT o0, o1, i1\n    }}\n"}
{"context": "Instruction: Convert following Python code into BSIL code.\nInput: #Python: \nview_3: f32[8, 512, 768] = torch.ops.aten.view.default(addmm_1, [8, 512, 768]);  addmm_1 = None\n\nAnswer: ", "target": "#BSIL: \nview_3<8, 512, 768> = view addmm_1 {{\n        !shape=[8, 512, 768]\n        INPUT i0, i1, i2: u64\n        o0: u64 = linear [i0, i1] [512, 1]\n        OUTPUT o0, i2\n    }}\n"}
{"context": "Instruction: Convert following Python code into BSIL code.\nInput: #Python: \npermute_2: f32[8, 12, 512, 64] = torch.ops.aten.permute.default(view_4, [0, 2, 1, 3]);  view_4 = None\n\nAnswer: ", "target": "#BSIL: \npermute_2<8, 12, 512, 64> = view view_4 {{\n          !shape=[8, 12, 512, 64]\n          INPUT i0, i1, i2, i3: u64\n          OUTPUT i0, i2, i1, i3\n    }}\n"}
{"context": "Instruction: Convert following Python code into BSIL code.\nInput: #Python: \nexpand: f32[8, 12, 512, 64] = torch.ops.aten.expand.default(permute_5, [8, 12, 512, 64]);  permute_5 = None\n\nAnswer: ", "target": "#BSIL: \nexpand<8, 12, 512, 64> = view permute_5 {{\n          !shape=[8, 12, 512, 64]\n          INPUT i0, i1, i2, i3: u64\n          OUTPUT i0, i1, i2, i3\n    }}\n"}
{"context": "Instruction: Convert following Python code into BSIL code.\nInput: #Python: \nclone: f32[8, 12, 512, 64] = torch.ops.aten.clone.default(expand, memory_format = torch.contiguous_format);  expand = None\n\nAnswer: ", "target": "#BSIL: \nclone<8, 12, 512, 64> = copy expand\n"}
{"context": "Instruction: Convert following Python code into BSIL code.\nInput: #Python: \nadd: f32[8, 12, 512, 512] = torch.ops.aten.add.Tensor(div, primals_8);  div = primals_8 = None\n\nAnswer: ", "target": "#BSIL: \nadd<8, 12, 512, 512> = map div primals_8 {{\n          !shape=[8, 12, 512, 512]\n          INPUT x, y: f32\n          z: f32 = div x y\n          OUTPUT z\n    }}\n"}
